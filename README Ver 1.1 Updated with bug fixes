AI Security Lab - Prompt Injection Training Platform
An interactive educational web application designed to teach cybersecurity professionals and developers about prompt injection techniques in AI systems. This platform provides a safe, controlled environment to explore AI vulnerabilities and learn defensive strategies.

🎯 Features
Interactive Tutorial: Step-by-step lessons on prompt injection fundamentals
Hands-on Lab: Test pre-built injection examples or create custom scenarios
Real-time Analysis: Automatic detection and classification of injection patterns
Educational Content: Comprehensive explanations of attack vectors and defenses
Security-First Design: Proper secret management and secure coding practices
🚀 Quick Start
Prerequisites
Python 3.11+
OpenAI API key (for live AI responses)
Installation
Clone the repository:
git clone https://github.com/yourusername/ai-security-lab.git
cd ai-security-lab
Install dependencies:
pip install -r requirements.txt
Set up environment variables:
export OPENAI_API_KEY="your-openai-api-key"
export SESSION_SECRET="your-session-secret"
Run the application:
python main.py
Open your browser to http://localhost:5000
📚 Usage
Tutorial Mode
Start with the step-by-step tutorial to learn:

What prompt injection is and why it matters
Common attack techniques and patterns
Defense strategies and best practices
Ethical considerations for security research
Lab Mode
Use the interactive lab to:

Test pre-built injection examples
Create and analyze custom scenarios
See real-time AI responses and pattern analysis
Understand injection success indicators
Example Categories
Beginner: Basic role confusion and instruction override
Intermediate: Context switching and prompt leaking
Advanced: Multi-step attacks and evasion techniques
🏗️ Architecture
Backend
Flask: Python web framework for routing and API endpoints
OpenAI Integration: Secure API communication for live AI responses
Pattern Detection: Educational analysis of injection techniques
Error Handling: Comprehensive exception handling for improved application stability
Frontend
Bootstrap 5: Responsive UI with dark theme
Vanilla JavaScript: Interactive features and real-time communication
Jinja2 Templates: Server-side rendering with component reusability
Interactive Navigation: Smooth tutorial progression and lab interface
Security Features
Environment-based secret management with secure key handling
Comprehensive input validation and XSS protection
CSRF protection with token-based security
Rate limiting to prevent abuse
Secure API response validation
Educational-only scope (no real harm possible)
🔧 Configuration
Environment Variables
OPENAI_API_KEY=your-openai-api-key    # Required for live AI responses
SESSION_SECRET=your-session-secret    # Flask session security
Deployment Options
Local Development
python main.py
Production (Gunicorn)
gunicorn --bind 0.0.0.0:5000 main:app
Docker
docker build -t ai-security-lab .
docker run -p 5000:5000 ai-security-lab
🔍 Analysis Features
Risk Assessment
High: Serious bypass attempts requiring immediate attention
Medium: Moderate security concerns with potential impact
Low: Minor manipulation attempts
🛡️ Security Considerations
This platform is designed for educational purposes only:

All examples are safe and demonstrate techniques without causing harm
Real AI responses are filtered and monitored
No sensitive data is processed or stored
Proper input validation prevents malicious use
🔄 Recent Updates
Version 1.2 (June 2025)

Major Security Hardening: Comprehensive security improvements across all frontend layers
Eliminated XSS risks by replacing innerHTML with safe DOM manipulation
Added comprehensive input validation and API response validation
Implemented CSRF protection with token support
Added rate limiting to prevent abuse
Enhanced error handling with secure logging practices
CSS Security: Removed injection risks, enhanced accessibility, security-conscious styling
Accessibility: Added WCAG 2.1 compliance features including focus indicators and screen reader support
Version 1.1 (June 2025)

Fixed deployment session management errors that prevented health checks
Resolved tutorial navigation buttons not functioning properly
Added comprehensive error handling for improved application stability
Enhanced deployment reliability with better exception management
🤝 Contributing
Fork the repository
Create a feature branch (git checkout -b feature/amazing-feature)
Commit your changes (git commit -m 'Add amazing feature')
Push to the branch (git push origin feature/amazing-feature)
Open a Pull Request
Development Guidelines
Follow PEP 8 style guidelines
Add tests for new features
Update documentation for any changes
Ensure security best practices
📄 License
This project is licensed under the MIT License - see the LICENSE file for details.

👤 Creator
Maria Singh
Cybersecurity Professional & AI Security Researcher
📧 info@agilesecuritytransformation.com
💼 LinkedIn
🏢 Agile Security Transformation

💬 Feedback
This project includes a built-in feedback system. You can submit feedback, bug reports, feature requests, and suggestions directly through the application interface at the bottom of any page.

🙏 Acknowledgments
OpenAI for providing the AI models used in demonstrations
Bootstrap team for the excellent CSS framework
The cybersecurity community for continuous feedback and improvements
Educational Use Only: This platform is designed for cybersecurity education and should only be used for learning and authorized security testing.
